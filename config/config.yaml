# Intelligent Development Assistant Configuration

# Model Configuration
# UNIFIED: Using OpenRouter API for all models (matches autogen_agents.yaml)
# Primary model: mistralai/devstral-2512:free (123B agentic coding model with function calling)
models:
  # OpenRouter Configuration (Primary - Production)
  openrouter:
    enabled: true
    api_key: "${OPENROUTER_API_KEY}"
    base_url: "https://openrouter.ai/api/v1"
    default_model: "mistralai/devstral-2512:free"
    alternative_models:
      - "kwaipilot/kat-coder-pro:free"
      - "nex-agi/deepseek-v3.1-nex-n1:free"
    max_retries: 3
    timeout: 120

  # Local Models Configuration (Fallback - Development)
  local:
    enabled: false  # Disabled by default, enable for offline development
    code_analyzer:
      primary: "codellama/CodeLlama-13b-Instruct-hf"
      alternative: "bigcode/starcoder2-15b"
      quantization: "4bit"
      max_tokens: 4096
      temperature: 0.3
      deployment: "local"

    documentation:
      primary: "meta-llama/Meta-Llama-3-8B-Instruct"
      alternative: "mistralai/Mistral-7B-Instruct-v0.2"
      quantization: "4bit"
      max_tokens: 2048
      temperature: 0.7
      deployment: "local"

    code_generation:
      primary: "deepseek-ai/deepseek-coder-33b-instruct"
      alternative: "codellama/CodeLlama-34b-Instruct-hf"
      quantization: "4bit"
      max_tokens: 4096
      temperature: 0.2
      deployment: "hf_api"

# Hugging Face API Configuration
huggingface:
  api_token: "${HF_API_TOKEN}"
  cache_dir: "./models_cache"
  use_auth_token: true
  trust_remote_code: false

# MCP Server Configuration
mcp_servers:
  github:
    enabled: true
    port: 3000
    host: "0.0.0.0"
    server_url: "http://localhost:3000/mcp/github"
    auth_token: "${GITHUB_TOKEN}"
    api_base: "https://api.github.com"
    timeout: 30
    retry_attempts: 3
    fallback_enabled: true
    # Rate limiting
    rate_limit_minute: 60
    rate_limit_hour: 1000
    burst_size: 10
    # Caching
    cache_enabled: true
    cache_ttl: 300  # 5 minutes
    # Security
    blocked_patterns:
      - "force_push"
      - "delete_repository"

  filesystem:
    enabled: true
    port: 3001
    host: "0.0.0.0"
    server_url: "http://localhost:3001/mcp/filesystem"
    timeout: 10
    retry_attempts: 2
    fallback_enabled: true
    max_file_size_mb: 10
    # Security - allowed paths
    allowed_paths:
      - "./workspace"
      - "./projects"
      - "./src"
      - "./config"
      - "./examples"
    # Blocked patterns (regex)
    blocked_patterns:
      - "\\.\\.\/"  # Directory traversal
      - "\/etc\/"   # System files
      - "\/root\/"  # Root directory
      - "\\.ssh\/"  # SSH keys
      - "\\.env$"   # Environment files (exact match)
    # Rate limiting
    rate_limit_minute: 100
    rate_limit_hour: 2000
    burst_size: 20
    # Caching
    cache_enabled: true
    cache_ttl: 60  # 1 minute for file operations

  memory:
    enabled: true
    port: 3002
    host: "0.0.0.0"
    server_url: "http://localhost:3002/mcp/memory"
    storage_backend: "sqlite"  # Best for local development - simple, fast, reliable
    sqlite_path: "./data/memory.db"  # Local file storage
    embedding_model: "all-MiniLM-L6-v2"  # Sentence-transformers model
    valid_memory_types:
      - "pattern"
      - "preference"
      - "solution"
      - "context"
      - "error"
    timeout: 5
    retry_attempts: 3
    fallback_enabled: true  # Falls back to JSON if server unavailable
    # Rate limiting
    rate_limit_minute: 200
    rate_limit_hour: 5000
    burst_size: 50
    # Caching
    cache_enabled: true
    cache_ttl: 300  # 5 minutes

  slack:
    enabled: true
    port: 3003
    host: "0.0.0.0"
    server_url: "http://localhost:3003/mcp/slack"
    bot_token: "${SLACK_BOT_TOKEN}"
    default_channel: "#dev-assistant"
    timeout: 15
    retry_attempts: 2
    fallback_enabled: true
    # Rate limiting (Slack has strict limits)
    rate_limit_minute: 20
    rate_limit_hour: 100
    burst_size: 5
    # Caching
    cache_enabled: false  # Don't cache messages

  codebasebuddy:
    enabled: true
    port: 3004
    host: "0.0.0.0"
    server_url: "http://localhost:3004/mcp/codebasebuddy"
    timeout: 60
    retry_attempts: 3
    fallback_enabled: true
    # Index configuration
    index_path: "./data/codebase_index"
    embedding_dimensions: 384  # Dimensions for all-MiniLM-L6-v2
    embedding_model: "all-MiniLM-L6-v2"  # Sentence-transformers model name
    scan_paths:
      - "./src"
      - "./mcp_servers"
      - "./config"
    exclude_patterns:
      - "__pycache__"
      - ".git"
      - ".venv"
      - "venv"
      - "node_modules"
      - ".pytest_cache"
      - ".mypy_cache"
      - "dist"
      - "build"
    exclude_files:
      - ".pyc"
      - ".pyo"
      - ".so"
      - ".dll"
      - ".exe"
    file_extensions:
      - ".py"
      - ".js"
      - ".ts"
      - ".jsx"
      - ".tsx"
      - ".java"
      - ".yaml"
      - ".yml"
      - ".json"
      - ".md"
    chunk_strategy: "function"  # 'function' for Python AST parsing, 'file' for simple chunking
    # Rate limiting
    rate_limit_minute: 100
    rate_limit_hour: 2000
    burst_size: 20
    # Caching
    cache_enabled: true
    cache_ttl: 300  # 5 minutes

  google_drive:
    enabled: false
    port: 3005
    host: "0.0.0.0"
    server_url: "http://localhost:3005/mcp/gdrive"
    credentials_file: "./config/google_credentials.json"
    timeout: 30
    retry_attempts: 3
    fallback_enabled: true
    # Rate limiting
    rate_limit_minute: 30
    rate_limit_hour: 500
    burst_size: 10
    # Caching
    cache_enabled: true
    cache_ttl: 600  # 10 minutes

  duckduckgo_search:
    enabled: false  # disabled: research agent now uses built-in duckduckgo_search library
    timeout: 10
    retry_attempts: 2
    fallback_enabled: true
    # Caching (aggressive for search results)
    cache_enabled: true
    cache_ttl: 3600  # 1 hour

# Agent Configuration
agents:
  code_analyzer:
    enabled: true
    max_concurrent_tasks: 3
    priority: 1
    tools: ["github", "filesystem"]
    memory_enabled: true

  documentation:
    enabled: true
    max_concurrent_tasks: 2
    priority: 2
    tools: ["github", "filesystem", "google_drive"]
    memory_enabled: true

  deployment:
    enabled: true
    max_concurrent_tasks: 1
    priority: 1
    tools: ["github", "filesystem", "slack"]
    memory_enabled: true

  research:
    enabled: true
    max_concurrent_tasks: 2
    priority: 2
    tools: ["github", "filesystem"]
    memory_enabled: true

  project_manager:
    enabled: true
    max_concurrent_tasks: 1
    priority: 0  # Highest priority (orchestrator)
    tools: ["github", "filesystem", "memory"]
    memory_enabled: true

  dev_workflow:
    enabled: false  # No factory exists for this agent
    max_concurrent_tasks: 2
    priority: 1
    tools: ["github", "filesystem"]
    memory_enabled: true

  communication:
    enabled: false  # No factory exists for this agent
    max_concurrent_tasks: 5
    priority: 3
    tools: ["slack", "google_drive", "memory"]
    memory_enabled: true

  code_generation:
    enabled: false  # No factory exists for this agent
    max_concurrent_tasks: 2
    priority: 1
    tools: ["github", "filesystem"]
    memory_enabled: true

  memory:
    enabled: false  # No factory exists for this agent
    max_concurrent_tasks: 10
    priority: 0  # Highest priority
    tools: ["memory", "filesystem"]
    memory_enabled: false  # Doesn't query itself

# Workflow Configuration
workflows:
  execution_mode: "hybrid"  # "sequential", "parallel", or "hybrid"
  max_parallel_tasks: 5
  task_timeout: 300  # seconds
  enable_task_queue: true
  priority_queue_enabled: true

  priorities:
    critical_fix: 0
    feature_development: 1
    documentation: 2
    maintenance: 3

# Memory Configuration
memory:
  short_term:
    ttl: 3600  # 1 hour
    max_entries: 1000

  medium_term:
    ttl: 2592000  # 30 days
    max_entries: 10000

  long_term:
    ttl: null  # permanent
    max_entries: 100000

  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  similarity_threshold: 0.7
  context_window_size: 4096
  max_context_entries: 5

# Performance Configuration
performance:
  gpu_enabled: true
  gpu_memory_fraction: 0.8
  cpu_threads: 8
  batch_size: 4
  max_concurrent_inferences: 3

  caching:
    enabled: true
    cache_backend: "redis"
    prompt_cache_ttl: 3600
    result_cache_ttl: 1800

  optimization:
    use_flash_attention: true
    gradient_checkpointing: true
    mixed_precision: "fp16"

# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "json"
  file: "./logs/dev_assistant.log"
  max_file_size: "100MB"
  backup_count: 5

  components:
    agents: "INFO"
    mcp: "DEBUG"
    models: "INFO"
    workflows: "INFO"
    memory: "DEBUG"

# Error Handling
error_handling:
  retry_strategy: "exponential_backoff"
  max_retries: 3
  initial_retry_delay: 1  # seconds
  max_retry_delay: 60
  enable_fallbacks: true
  graceful_degradation: true

  alert_on_failure: true
  alert_channels: ["slack"]

# Feature Flags
features:
  auto_fix_enabled: false  # Automatically apply code fixes
  learning_enabled: true   # Learn from interactions
  proactive_suggestions: true
  batch_processing: true
  async_execution: true
